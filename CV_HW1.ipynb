{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xoxonut/nycu-cv-113-2/blob/main/CV_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ms-LIvVfC1tm",
        "outputId": "56d3d576-aea1-4a42-95ab-2f536f811b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf \"/content/drive/MyDrive/hw1-data.tar.gz\" -C \"/content\" > /dev/null 2>&1\n",
        "!du -sh \"/content/data\"\n",
        "!awk 'BEGIN {sum=0} /^[0-9]+$/ {sum+=$1} END {print sum}' <(find \"/content/data/train\" -type f | wc -l) <(find \"/content/data/val\" -type f | wc -l)"
      ],
      "metadata": {
        "id": "545JUVYt90Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c2cfa4-be72-4ade-a896-ed5fb810651b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.5G\t/content/data\n",
            "21024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.models import resnet50,ResNet50_Weights\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch import nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "-bKg2bCHly22"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms():\n",
        "  train_transform = v2.Compose([\n",
        "      v2.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "      v2.Resize((224,224)),\n",
        "      v2.ColorJitter(hue=.05, saturation=.05),\n",
        "      v2.RandomHorizontalFlip(),\n",
        "      v2.RandomRotation(20),\n",
        "      v2.ToTensor(),\n",
        "      v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  test_transform = v2.Compose([\n",
        "      v2.Lambda(lambda img: img.convert(\"RGB\")),\n",
        "      v2.Resize((224,224)),\n",
        "      v2.ToTensor(),\n",
        "      v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  return train_transform, test_transform"
      ],
      "metadata": {
        "id": "a7tRcYvyhg29"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(train_transform,test_transform,batch_size):\n",
        "  train_set = datasets.ImageFolder(\"/content/data/train\",transform=train_transform)\n",
        "  val_set = datasets.ImageFolder(\"/content/data/val\",transform=test_transform)\n",
        "  train_names = {v:int(k) for k,v in train_set.class_to_idx.items()}\n",
        "  val_names = {v:int(k) for k,v in val_set.class_to_idx.items()}\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
        "  val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  class TestDataSet(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "      self.root_dir = root_dir\n",
        "      self.transform = transform\n",
        "      valid_exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\")\n",
        "      self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.lower().endswith(valid_exts)]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      image_path = self.image_paths[index]\n",
        "      image = Image.open(image_path)\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "      file_name = os.path.basename(image_path)\n",
        "      name_only = os.path.splitext(file_name)[0]\n",
        "      return image,name_only\n",
        "  test_set = TestDataSet(\"/content/data/test\",transform=test_transform)\n",
        "  test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "  return train_loader,val_loader,test_loader,train_names,val_names"
      ],
      "metadata": {
        "id": "XxVYB8cBok4s"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model,train_loader,optimizer,criterion,device,names):\n",
        "  model.train()\n",
        "  total_loss, correct, total = 0, 0, 0\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    predicted = torch.argmax(outputs, dim=1)\n",
        "    mapped_predicted = [names[p.item()] for p in predicted]\n",
        "    correct += sum(p == l for p, l in zip(mapped_predicted, labels))\n",
        "    total += labels.size(0)\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  avg_acc = correct / total * 100\n",
        "  return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "B7jaV7ANqFes"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model,val_loader,criterion,device,name):\n",
        "  model.eval()\n",
        "  total_loss, correct, total = 0, 0, 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      predicted = torch.argmax(outputs, dim=1)\n",
        "      mapped_predicted = [names[p.item()] for p in predicted]\n",
        "      correct += sum(p == l for p, l in zip(mapped_predicted, labels))\n",
        "      total += labels.size(0)\n",
        "  avg_loss = total_loss / len(val_loader)\n",
        "  avg_acc = correct / total * 100\n",
        "  return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "xWc6_O6ornPO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_loader,device):\n",
        "  model.eval()\n",
        "  correct, total = 0, 0\n",
        "  predictions = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, file_names in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      outputs = model(inputs)\n",
        "      preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "      for file_name, pred in zip(file_names, preds):\n",
        "        predictions.append({\"image_name\": file_name,\n",
        "                            \"pred_label\": pred.item()})\n",
        "  return predictions\n"
      ],
      "metadata": {
        "id": "4RMbQx9fr_i2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_RestNet50(num_classes):\n",
        "  model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "  num_ftrs = model.fc.in_features\n",
        "  model.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, num_classes)\n",
        "  )\n",
        "  for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "  for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "  for p in model.layer4.parameters():\n",
        "    p.requires_grad = True\n",
        "  return model"
      ],
      "metadata": {
        "id": "IvI2p675ntpp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_accuracy(train_losses, val_losses, train_accs, val_accs):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot losses\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accs, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "K2jbIxK2vOuc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_model_size(model):\n",
        "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())  # in bytes\n",
        "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())  # in bytes\n",
        "    total_size = (param_size + buffer_size) / (1024 ** 2)  # Convert to MB\n",
        "    print(f\"Model size: {total_size:.2f} MB\")\n"
      ],
      "metadata": {
        "id": "T35AMw9OvacU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  train_transform,test_transform = get_transforms()\n",
        "  train_loader,val_loader,test_loader,t_names,v_names = create_dataloader(train_transform,test_transform,32)\n",
        "  model = init_RestNet50(100)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.AdamW(model.parameters(), lr=0.001,weight_decay=0.01)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n",
        "  epochs = 10\n",
        "  train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
        "  print_model_size(model)\n",
        "  for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device,t_names)\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device,v_names)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    torch.save(model,\"/content/drive/MyDrive/full_model.pth\")\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}% - Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.2f}%\")\n",
        "  plot_loss_accuracy(train_losses, val_losses, train_accs, val_accs)\n",
        "  res = test_model(model,test_loader,device)\n",
        "  df = pd.DataFrame(res)\n",
        "  df.to_csv(\"/content/drive/MyDrive/prediction.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "6yOAAexJk2iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6143ee9-3f08-4324-aee7-58cdfb3d7cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size: 94.08 MB\n"
          ]
        }
      ]
    }
  ]
}